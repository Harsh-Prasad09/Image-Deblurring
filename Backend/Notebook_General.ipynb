{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T21:47:42.987133Z",
     "iopub.status.busy": "2025-03-31T21:47:42.986884Z",
     "iopub.status.idle": "2025-03-31T21:47:47.422640Z",
     "shell.execute_reply": "2025-03-31T21:47:47.421818Z",
     "shell.execute_reply.started": "2025-03-31T21:47:42.987113Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-29T08:42:37.392216Z",
     "iopub.status.busy": "2025-03-29T08:42:37.391890Z",
     "iopub.status.idle": "2025-03-29T08:42:40.662094Z",
     "shell.execute_reply": "2025-03-29T08:42:40.661405Z",
     "shell.execute_reply.started": "2025-03-29T08:42:37.392186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.021464Z",
     "iopub.status.busy": "2025-03-28T14:45:48.021236Z",
     "iopub.status.idle": "2025-03-28T14:45:48.040429Z",
     "shell.execute_reply": "2025-03-28T14:45:48.039508Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.021441Z"
    },
    "id": "3DqvScj08wH8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.042251Z",
     "iopub.status.busy": "2025-03-28T14:45:48.041945Z",
     "iopub.status.idle": "2025-03-28T14:45:48.060829Z",
     "shell.execute_reply": "2025-03-28T14:45:48.060024Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.042223Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"vasukipatel/face-recognition-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.061778Z",
     "iopub.status.busy": "2025-03-28T14:45:48.061519Z",
     "iopub.status.idle": "2025-03-28T14:45:48.080712Z",
     "shell.execute_reply": "2025-03-28T14:45:48.079856Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.061757Z"
    },
    "id": "oYnubtVI9C6j",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to apply Gaussian blur to an image\n",
    "def apply_gaussian_blur(image, kernel_size=(5, 5), sigma=1):\n",
    "    \"\"\"Applies Gaussian blur to the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - kernel_size: Size of the Gaussian kernel.\n",
    "    - sigma: Standard deviation for the Gaussian kernel.\n",
    "\n",
    "    Returns:\n",
    "    - Blurred image.\n",
    "    \"\"\"\n",
    "    return cv2.GaussianBlur(image, kernel_size, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.081827Z",
     "iopub.status.busy": "2025-03-28T14:45:48.081511Z",
     "iopub.status.idle": "2025-03-28T14:45:48.095887Z",
     "shell.execute_reply": "2025-03-28T14:45:48.095182Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.081806Z"
    },
    "id": "bC5xrStJ9BVR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create directories for saving the paired images\n",
    "def create_dirs(output_dir, sharp_dir_name='sharp', blurred_dir_name='blurred'):\n",
    "    \"\"\"Creates directories for storing sharp and blurred images.\"\"\"\n",
    "    sharp_dir = os.path.join(output_dir, sharp_dir_name)\n",
    "    blurred_dir = os.path.join(output_dir, blurred_dir_name)\n",
    "\n",
    "    os.makedirs(sharp_dir, exist_ok=True)\n",
    "    os.makedirs(blurred_dir, exist_ok=True)\n",
    "\n",
    "    return sharp_dir, blurred_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.097143Z",
     "iopub.status.busy": "2025-03-28T14:45:48.096907Z",
     "iopub.status.idle": "2025-03-28T14:45:48.114276Z",
     "shell.execute_reply": "2025-03-28T14:45:48.113484Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.097115Z"
    },
    "id": "eaDNL99h83nG",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Process and save the paired dataset\n",
    "def create_paired_dataset(input_dir, output_dir, kernel_size=(15, 15), sigma=3):\n",
    "    \"\"\"Creates a paired dataset of sharp and blurred images.\n",
    "\n",
    "    Parameters:\n",
    "    - input_dir: Directory containing the original (sharp) images.\n",
    "    - output_dir: Directory where the sharp and blurred images will be saved.\n",
    "    - kernel_size: Size of the Gaussian kernel.\n",
    "    - sigma: Standard deviation for the Gaussian kernel.\n",
    "    \"\"\"\n",
    "    sharp_dir, blurred_dir = create_dirs(output_dir)\n",
    "\n",
    "    # Loop through all images in the input directory\n",
    "    for img_name in tqdm(os.listdir(input_dir)):\n",
    "        img_path = os.path.join(input_dir, img_name)\n",
    "\n",
    "        # Open the image and convert it to a numpy array\n",
    "        image = np.array(Image.open(img_path))\n",
    "\n",
    "        # Apply Gaussian blur to the image\n",
    "        blurred_image = apply_gaussian_blur(image, kernel_size, sigma)\n",
    "\n",
    "        # Convert back to PIL Image for saving\n",
    "        sharp_image_pil = Image.fromarray(image)\n",
    "        blurred_image_pil = Image.fromarray(blurred_image)\n",
    "\n",
    "        # Save the sharp and blurred images in their respective directories\n",
    "        sharp_image_pil.save(os.path.join(sharp_dir, img_name))\n",
    "        blurred_image_pil.save(os.path.join(blurred_dir, img_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:45:48.116664Z",
     "iopub.status.busy": "2025-03-28T14:45:48.116414Z",
     "iopub.status.idle": "2025-03-28T14:46:00.107369Z",
     "shell.execute_reply": "2025-03-28T14:46:00.106507Z",
     "shell.execute_reply.started": "2025-03-28T14:45:48.116642Z"
    },
    "id": "xzH062b683Ee",
    "outputId": "3756b785-9269-4bdd-ce4e-5fbecbbf8c6b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "input_dir = '/kaggle/input/face-recognition-dataset/Faces/Faces'  # Directory containing your sharp images\n",
    "output_dir = 'images'  # Directory to save the sharp and blurred images\n",
    "\n",
    "# Create paired dataset with Gaussian blur (kernel size 5x5 and sigma 1)\n",
    "create_paired_dataset(input_dir, output_dir, kernel_size=(25, 25), sigma=3)\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Path to the folder you want to zip\n",
    "\n",
    "# Output path for the zip file (without extension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:00.109084Z",
     "iopub.status.busy": "2025-03-28T14:46:00.108868Z",
     "iopub.status.idle": "2025-03-28T14:46:00.114232Z",
     "shell.execute_reply": "2025-03-28T14:46:00.113491Z",
     "shell.execute_reply.started": "2025-03-28T14:46:00.109066Z"
    },
    "id": "ndWOyZyr_Y-Z",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "folder_to_zip = 'sharp'\n",
    "output_zip = 'sharp_zip'\n",
    "\n",
    "# Create a zip archive\n",
    "shutil.make_archive(output_zip, 'zip', folder_to_zip)\n",
    "\n",
    "print(f\"Folder zipped as {output_zip}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:00.115612Z",
     "iopub.status.busy": "2025-03-28T14:46:00.115279Z",
     "iopub.status.idle": "2025-03-28T14:46:03.678836Z",
     "shell.execute_reply": "2025-03-28T14:46:03.677951Z",
     "shell.execute_reply.started": "2025-03-28T14:46:00.115563Z"
    },
    "id": "aRkFIUaa_qoW",
    "outputId": "876313bc-ffc4-4f31-dd1a-fd0644af71a2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.680176Z",
     "iopub.status.busy": "2025-03-28T14:46:03.679941Z",
     "iopub.status.idle": "2025-03-28T14:46:03.685092Z",
     "shell.execute_reply": "2025-03-28T14:46:03.684086Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.680157Z"
    },
    "id": "53gD9Mk3_pcy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torchvision.models import squeezenet1_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.686304Z",
     "iopub.status.busy": "2025-03-28T14:46:03.686019Z",
     "iopub.status.idle": "2025-03-28T14:46:03.701940Z",
     "shell.execute_reply": "2025-03-28T14:46:03.701080Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.686273Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchmetrics.functional import structural_similarity_index_measure as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.702973Z",
     "iopub.status.busy": "2025-03-28T14:46:03.702754Z",
     "iopub.status.idle": "2025-03-28T14:46:03.720230Z",
     "shell.execute_reply": "2025-03-28T14:46:03.719425Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.702953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the Convolutional Autoencoder\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "        # Encoder: Convolutional layers with downsampling\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # 128x128 -> 64x64\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 64x64 -> 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(512, 1024, kernel_size=3, stride=2, padding=1),  # 10x10 -> 5x5\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Decoder: Transposed convolutional layers with upsampling\n",
    "        self.decoder = nn.Sequential(\n",
    "          nn.ConvTranspose2d(1024, 512, kernel_size=3, stride=2, padding=1, output_padding=1),  # 5x5 -> 10x10\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),  # 10x10 -> 20x20\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 20x20 -> 40x40\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 40x40 -> 80x80\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # 80x80 -> 160x160\n",
    "            # nn.ReLU(),\n",
    "            # nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 160X160 -> 320x320\n",
    "            nn.Sigmoid()  # Use sigmoid to ensure the output is between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.721134Z",
     "iopub.status.busy": "2025-03-28T14:46:03.720946Z",
     "iopub.status.idle": "2025-03-28T14:46:03.742376Z",
     "shell.execute_reply": "2025-03-28T14:46:03.741690Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.721118Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Custom dataset to load sharp and blurred images\n",
    "class DeblurDataset(Dataset):\n",
    "    def __init__(self, sharp_dir, blurred_dir, transform=None):\n",
    "        self.sharp_dir = sharp_dir\n",
    "        self.blurred_dir = blurred_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(sharp_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        sharp_path = os.path.join(self.sharp_dir, img_name)\n",
    "        blurred_path = os.path.join(self.blurred_dir, img_name)\n",
    "\n",
    "        sharp_image = Image.open(sharp_path).convert('RGB')\n",
    "        blurred_image = Image.open(blurred_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            sharp_image = self.transform(sharp_image)\n",
    "            blurred_image = self.transform(blurred_image)\n",
    "\n",
    "        return blurred_image, sharp_image  # Input: blurred, Target: sharp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.743499Z",
     "iopub.status.busy": "2025-03-28T14:46:03.743253Z",
     "iopub.status.idle": "2025-03-28T14:46:03.798390Z",
     "shell.execute_reply": "2025-03-28T14:46:03.797655Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.743479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "squeezenet = squeezenet1_1(pretrained=True).features[:8].cuda()\n",
    "\n",
    "\n",
    "def perceptual_loss(output, target):\n",
    "   output_features = squeezenet(output)\n",
    "   target_features = squeezenet(target)\n",
    "   return nn.MSELoss()(output_features, target_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.799502Z",
     "iopub.status.busy": "2025-03-28T14:46:03.799266Z",
     "iopub.status.idle": "2025-03-28T14:46:03.911214Z",
     "shell.execute_reply": "2025-03-28T14:46:03.910470Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.799483Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#    baad me uncomment karna hai\n",
    "def ssim_loss(output, target):\n",
    "    return 1 - ssim(output, target)\n",
    "\n",
    "# Instantiate the dataset and dataloader\n",
    "sharp_dir = '/kaggle/working/images/sharp'  # Replace with the path to your sharp images\n",
    "blurred_dir = '/kaggle/working/images/blurred'  # Replace with the path to your blurred images\n",
    "print(\"Creating Data\")\n",
    "dataset = DeblurDataset(sharp_dir, blurred_dir, transform=transform)\n",
    "print(\"Loading Data\")\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print(\"Loading Model\")\n",
    "# Model, loss function, and optimizer\n",
    "model = ConvAutoencoder().cuda()  # Move the model to GPU if available\n",
    "criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:46:03.912449Z",
     "iopub.status.busy": "2025-03-28T14:46:03.912143Z",
     "iopub.status.idle": "2025-03-28T14:47:45.960870Z",
     "shell.execute_reply": "2025-03-28T14:47:45.960007Z",
     "shell.execute_reply.started": "2025-03-28T14:46:03.912415Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"Training Started\")\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        blurred_images, sharp_images = data\n",
    "        blurred_images = blurred_images.cuda()\n",
    "        sharp_images = sharp_images.cuda()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(blurred_images)\n",
    "        loss_mse = nn.MSELoss()(outputs, sharp_images)\n",
    "        loss_perceptual = perceptual_loss(outputs, sharp_images)\n",
    "        loss_ssim = ssim_loss(outputs, sharp_images)\n",
    "        loss = loss_mse + 0.01 * loss_perceptual + 0.9 * loss_ssim\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:47:45.965951Z",
     "iopub.status.busy": "2025-03-28T14:47:45.965708Z",
     "iopub.status.idle": "2025-03-28T14:47:45.974319Z",
     "shell.execute_reply": "2025-03-28T14:47:45.973441Z",
     "shell.execute_reply.started": "2025-03-28T14:47:45.965930Z"
    },
    "id": "11x1ZFtf_pZd",
    "outputId": "7e6bb331-5480-4868-8115-a3629892229c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Training completed!\")\n",
    "def display_images(model, dataloader, num_images):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(10, num_images * 3))\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        for i, (blurred_images, sharp_images) in enumerate(dataloader):\n",
    "            if i >= num_images:\n",
    "                break\n",
    "\n",
    "            # Move images to GPU if available\n",
    "            blurred_images = blurred_images.cuda()\n",
    "            sharp_images = sharp_images.cuda()\n",
    "\n",
    "            # Forward pass to get reconstructed (deblurred) images\n",
    "            reconstructed_images = model(blurred_images)\n",
    "\n",
    "            # Move images back to CPU and detach from computation graph\n",
    "            blurred_images = blurred_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "            sharp_images = sharp_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "            reconstructed_images = reconstructed_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "            # Display images\n",
    "            for j in range(len(blurred_images)):\n",
    "                if i * len(blurred_images) + j >= num_images:\n",
    "                    break\n",
    "\n",
    "                idx = i * len(blurred_images) + j\n",
    "\n",
    "                # Blurred image\n",
    "                axes[idx, 0].imshow(blurred_images[j])\n",
    "                axes[idx, 0].set_title(\"Blurred\")\n",
    "                axes[idx, 0].axis(\"off\")\n",
    "\n",
    "                # Reconstructed (Deblurred) image\n",
    "                axes[idx, 1].imshow(reconstructed_images[j])\n",
    "                axes[idx, 1].set_title(\"Reconstructed\")\n",
    "                axes[idx, 1].axis(\"off\")\n",
    "\n",
    "                # Sharp (Original) image\n",
    "                axes[idx, 2].imshow(sharp_images[j])\n",
    "                axes[idx, 2].set_title(\"Sharp\")\n",
    "                axes[idx, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:47:45.975472Z",
     "iopub.status.busy": "2025-03-28T14:47:45.975225Z",
     "iopub.status.idle": "2025-03-28T14:47:51.167317Z",
     "shell.execute_reply": "2025-03-28T14:47:51.166381Z",
     "shell.execute_reply.started": "2025-03-28T14:47:45.975452Z"
    },
    "id": "U0Z3Aj_qBlR8",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Call the function to display the images\n",
    "display_images(model, dataloader, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:47:51.168393Z",
     "iopub.status.busy": "2025-03-28T14:47:51.168147Z",
     "iopub.status.idle": "2025-03-28T14:47:51.242463Z",
     "shell.execute_reply": "2025-03-28T14:47:51.241545Z",
     "shell.execute_reply.started": "2025-03-28T14:47:51.168365Z"
    },
    "id": "sg5KpY0XBHKw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example function to save model weights after training\n",
    "torch.save(model.state_dict(), 'deblur_autoencoder.pth')\n",
    "# model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:47:51.243666Z",
     "iopub.status.busy": "2025-03-28T14:47:51.243324Z",
     "iopub.status.idle": "2025-03-28T14:47:51.277604Z",
     "shell.execute_reply": "2025-03-28T14:47:51.276878Z",
     "shell.execute_reply.started": "2025-03-28T14:47:51.243639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Data transforms\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((160, 160)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "# squeezenet = squeezenet1_1(pretrained=True).features[:8].cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:47:51.278684Z",
     "iopub.status.busy": "2025-03-28T14:47:51.278380Z",
     "iopub.status.idle": "2025-03-28T14:47:51.386709Z",
     "shell.execute_reply": "2025-03-28T14:47:51.385766Z",
     "shell.execute_reply.started": "2025-03-28T14:47:51.278653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Instantiate the dataset and dataloader\n",
    "# sharp_dir = '/kaggle/input/text-image-with-motion-blur/images/images/resizeimage'  # Replace with the path to your sharp images\n",
    "# blurred_dir = '/kaggle/input/text-image-with-motion-blur/images/images/horizonal_mb'  # Replace with the path to your blurred images\n",
    "# print(\"Creating Data\")\n",
    "# dataset = DeblurDataset(sharp_dir, blurred_dir, transform=transform)\n",
    "# print(\"Loading Data\")\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "# print(\"Loading Model\")\n",
    "# # Model, loss function, and optimizer\n",
    "# model = ConvAutoencoder().cuda()  # Move the model to GPU if available\n",
    "# criterion = nn.MSELoss()  # Mean Squared Error loss for reconstruction\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T15:28:29.769954Z",
     "iopub.status.busy": "2025-03-28T15:28:29.769618Z",
     "iopub.status.idle": "2025-03-28T15:30:09.797737Z",
     "shell.execute_reply": "2025-03-28T15:30:09.796943Z",
     "shell.execute_reply.started": "2025-03-28T15:28:29.769928Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Training loop\n",
    "# print(\"Training Started\")\n",
    "# num_epochs = 50\n",
    "# for epoch in range(num_epochs):\n",
    "#     running_loss = 0.0\n",
    "#     for data in dataloader:\n",
    "#         blurred_images, sharp_images = data\n",
    "#         blurred_images = blurred_images.cuda()\n",
    "#         sharp_images = sharp_images.cuda()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(blurred_images)\n",
    "#         loss_mse = nn.MSELoss()(outputs, sharp_images)\n",
    "#         loss_perceptual = perceptual_loss(outputs, sharp_images)\n",
    "#         loss_ssim = ssim_loss(outputs, sharp_images)\n",
    "#         loss = loss_mse + 0.01 * loss_perceptual + 0.9 * loss_ssim\n",
    "#         # Backward pass and optimization\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         running_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T15:35:46.207898Z",
     "iopub.status.busy": "2025-03-28T15:35:46.207530Z",
     "iopub.status.idle": "2025-03-28T15:35:51.582612Z",
     "shell.execute_reply": "2025-03-28T15:35:51.581678Z",
     "shell.execute_reply.started": "2025-03-28T15:35:46.207872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(\"Training completed!\")\n",
    "# # Call the function to display the images\n",
    "# display_images(model, dataloader, num_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T15:27:43.907738Z",
     "iopub.status.busy": "2025-03-28T15:27:43.907377Z",
     "iopub.status.idle": "2025-03-28T15:27:44.027426Z",
     "shell.execute_reply": "2025-03-28T15:27:44.026461Z",
     "shell.execute_reply.started": "2025-03-28T15:27:43.907710Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Example function to save model weights after training\n",
    "torch.save(model.state_dict(), 'deblur_autoencoder1.pth')\n",
    "# model.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:17.973343Z",
     "iopub.status.busy": "2025-03-28T14:48:17.973039Z",
     "iopub.status.idle": "2025-03-28T14:48:17.977340Z",
     "shell.execute_reply": "2025-03-28T14:48:17.976311Z",
     "shell.execute_reply.started": "2025-03-28T14:48:17.973316Z"
    },
    "id": "hMyV8ZqVBHHY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "# def resize_image_opencv(image_path, output_path):\n",
    "#     image = cv2.imread(image_path)\n",
    "#     resized_image = cv2.resize(image, (160, 160))  # Resize to 160x160\n",
    "#     cv2.imwrite(output_path, resized_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:17.978673Z",
     "iopub.status.busy": "2025-03-28T14:48:17.978392Z",
     "iopub.status.idle": "2025-03-28T14:48:17.991439Z",
     "shell.execute_reply": "2025-03-28T14:48:17.990479Z",
     "shell.execute_reply.started": "2025-03-28T14:48:17.978651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import torch\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def save_reconstructed_images(model, dataloader, num_images, output_dir='final prod/sharp_final/blurred'):\n",
    "#     model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)  # Create the output directory if it doesn't exist\n",
    "\n",
    "#     with torch.no_grad():  # Disable gradient calculation for inference\n",
    "#         image_count = 0\n",
    "#         for i, (blurred_images, sharp_images) in enumerate(dataloader):\n",
    "#             if image_count >= num_images:\n",
    "#                 break\n",
    "\n",
    "#             # Move images to GPU if available\n",
    "#             blurred_images = blurred_images.cuda()\n",
    "            \n",
    "#             # Forward pass to get reconstructed (deblurred) images\n",
    "#             reconstructed_images = model(blurred_images)\n",
    "\n",
    "#             # Move images back to CPU and detach from computation graph\n",
    "#             reconstructed_images = reconstructed_images.cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "#             # Save images\n",
    "#             for j in range(len(reconstructed_images)):\n",
    "#                 if image_count >= num_images:\n",
    "#                     break\n",
    "\n",
    "#                 output_path = os.path.join(output_dir, f\"reconstructed_{image_count+1}.png\")\n",
    "                \n",
    "#                 plt.imsave(output_path, reconstructed_images[j])  # Save image\n",
    "#                 image_count += 1\n",
    "\n",
    "#     print(f\"Reconstructed images saved in '{output_dir}'.\")\n",
    "\n",
    "# # Example usage\n",
    "# # save_reconstructed_images(model, dataloader, num_images=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:17.992555Z",
     "iopub.status.busy": "2025-03-28T14:48:17.992328Z",
     "iopub.status.idle": "2025-03-28T14:48:18.012330Z",
     "shell.execute_reply": "2025-03-28T14:48:18.011484Z",
     "shell.execute_reply.started": "2025-03-28T14:48:17.992536Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "\n",
    "# def resize_images_opencv(input_dir, output_dir):\n",
    "#     if not os.path.exists(output_dir):\n",
    "#         os.makedirs(output_dir)  # Create output directory if not exists\n",
    "\n",
    "#     for filename in os.listdir(input_dir):\n",
    "#         input_path = os.path.join(input_dir, filename)\n",
    "#         output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "#         # Read and resize the image\n",
    "#         image = cv2.imread(input_path)\n",
    "#         if image is None:\n",
    "#             continue  # Skip invalid images\n",
    "\n",
    "#         resized_image = cv2.resize(image, (160, 160))\n",
    "#         cv2.imwrite(output_path, resized_image)\n",
    "    \n",
    "#     print(f\"Resized images saved in {output_dir}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:18.013492Z",
     "iopub.status.busy": "2025-03-28T14:48:18.013213Z",
     "iopub.status.idle": "2025-03-28T14:48:18.032032Z",
     "shell.execute_reply": "2025-03-28T14:48:18.031261Z",
     "shell.execute_reply.started": "2025-03-28T14:48:18.013464Z"
    },
    "id": "yVa0VN1yBHEk",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# resize_images_opencv(\"final prod/resize\", \"final prod/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:18.032932Z",
     "iopub.status.busy": "2025-03-28T14:48:18.032705Z",
     "iopub.status.idle": "2025-03-28T14:48:18.047089Z",
     "shell.execute_reply": "2025-03-28T14:48:18.046285Z",
     "shell.execute_reply.started": "2025-03-28T14:48:18.032913Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# create_paired_dataset('final prod/output', 'final prod/sharp_final', kernel_size=(25, 25), sigma=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:18.048127Z",
     "iopub.status.busy": "2025-03-28T14:48:18.047839Z",
     "iopub.status.idle": "2025-03-28T14:48:18.061014Z",
     "shell.execute_reply": "2025-03-28T14:48:18.060380Z",
     "shell.execute_reply.started": "2025-03-28T14:48:18.048098Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sharp_dir = 'final prod/sharp_final/sharp'  # Replace with the path to your sharp images\n",
    "# blurred_dir = 'final prod/sharp_final/blurred'  # Replace with the path to your blurred images\n",
    "# print(\"Creating Data\")\n",
    "# dataset = DeblurDataset(sharp_dir, blurred_dir, transform=transform)\n",
    "# print(\"Loading Data\")\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "# print(\"Loading Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:18.062093Z",
     "iopub.status.busy": "2025-03-28T14:48:18.061810Z",
     "iopub.status.idle": "2025-03-28T14:48:18.074540Z",
     "shell.execute_reply": "2025-03-28T14:48:18.073905Z",
     "shell.execute_reply.started": "2025-03-28T14:48:18.062066Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # dataset = DeblurDataset(sharp_dir='final prod/sharp_final/sharp', blurred_dir='final prod/sharp_final/blurred', transform=transform)\n",
    "# # dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "# save_reconstructed_images(model, dataloader, output_dir='pred_output', num_images=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-28T14:48:18.075723Z",
     "iopub.status.busy": "2025-03-28T14:48:18.075434Z",
     "iopub.status.idle": "2025-03-28T14:48:18.089086Z",
     "shell.execute_reply": "2025-03-28T14:48:18.088407Z",
     "shell.execute_reply.started": "2025-03-28T14:48:18.075703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# sharp_dir = 'final prod/sharp_final/sharp'  # Replace with the path to your sharp images\n",
    "# blurred_dir = 'final prod/sharp_final/sharp'  # Replace with the path to your blurred images\n",
    "# print(\"Creating Data\")\n",
    "# dataset = DeblurDataset(sharp_dir, blurred_dir, transform=transform)\n",
    "# print(\"Loading Data\")\n",
    "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "# print(\"Loading Model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 363608,
     "sourceId": 717840,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 959963,
     "sourceId": 1624149,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6991089,
     "sourceId": 11197604,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
